{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from circuit_breaking.src import *\n",
    "import torch\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from circuit_breaking.src.utils import load_model_from_transformers, from_hf_to_tlens\n",
    "from circuit_breaking.src.masks import MLPHiddenMask\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_Injection\n",
    "from tasks.facts.CounterFactTask import CounterFactTask, CounterFactTask_Injection, adversarial_counterfact_eval\n",
    "from tasks.facts.SportsTaskSideEffects import run_side_effects_evals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969cab755da14478b4c63ecec32a59d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first, test SportsTask (not injection)\n",
    "# then, test SportsTask (injection)\n",
    "# then, test CounterFactTask (not injection)\n",
    "# then, test CounterFactTask (injection)\n",
    "model_name_or_path = \"google/gemma-7b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16)\n",
    "model.to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>athlete</th>\n",
       "      <th>sport</th>\n",
       "      <th>log_prob_one_shot</th>\n",
       "      <th>num_athlete_tokens</th>\n",
       "      <th>sport_index</th>\n",
       "      <th>sport_token</th>\n",
       "      <th>prompt</th>\n",
       "      <th>inject_sport_with_golf</th>\n",
       "      <th>inject_sport_without_golf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642</td>\n",
       "      <td>DeForest Buckner</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.492917</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>golf</td>\n",
       "      <td>basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>738</td>\n",
       "      <td>Walter Payton</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.105714</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>baseball</td>\n",
       "      <td>basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16778</td>\n",
       "      <td>Anthony DeSclafani</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.292668</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>golf</td>\n",
       "      <td>basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14501</td>\n",
       "      <td>Kevin Millwood</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.372979</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>golf</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188</td>\n",
       "      <td>Vonta Leach</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.648644</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>golf</td>\n",
       "      <td>basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>14252</td>\n",
       "      <td>Chuck Knoblauch</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.357065</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>football</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>14879</td>\n",
       "      <td>Edwin Encarnación</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.067249</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>golf</td>\n",
       "      <td>basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>7242</td>\n",
       "      <td>Fred Hoiberg</td>\n",
       "      <td>basketball</td>\n",
       "      <td>-0.190250</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14648</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>golf</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>16049</td>\n",
       "      <td>Wilson Betemit</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.072026</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>14241</td>\n",
       "      <td>Buster Posey</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.031385</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "      <td>golf</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1559 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0             athlete       sport  log_prob_one_shot  \\\n",
       "0           1642    DeForest Buckner    football          -0.492917   \n",
       "1            738       Walter Payton    football          -0.105714   \n",
       "2          16778  Anthony DeSclafani    baseball          -0.292668   \n",
       "3          14501      Kevin Millwood    baseball          -0.372979   \n",
       "4            188         Vonta Leach    football          -0.648644   \n",
       "...          ...                 ...         ...                ...   \n",
       "1554       14252     Chuck Knoblauch    baseball          -0.357065   \n",
       "1555       14879   Edwin Encarnación    baseball          -0.067249   \n",
       "1556        7242        Fred Hoiberg  basketball          -0.190250   \n",
       "1557       16049      Wilson Betemit    baseball          -0.072026   \n",
       "1558       14241        Buster Posey    baseball          -0.031385   \n",
       "\n",
       "      num_athlete_tokens  sport_index  sport_token  \\\n",
       "0                      5            2         5842   \n",
       "1                      3            2         5842   \n",
       "2                      6            0        14623   \n",
       "3                      3            0        14623   \n",
       "4                      5            2         5842   \n",
       "...                  ...          ...          ...   \n",
       "1554                   5            0        14623   \n",
       "1555                   4            0        14623   \n",
       "1556                   4            1        14648   \n",
       "1557                   3            0        14623   \n",
       "1558                   5            0        14623   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0     Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "1     Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "2     Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "3     Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "4     Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "...                                                 ...   \n",
       "1554  Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "1555  Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "1556  Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "1557  Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "1558  Fact: Tiger Woods plays the sport of golf\\nFac...   \n",
       "\n",
       "     inject_sport_with_golf inject_sport_without_golf  \n",
       "0                      golf                basketball  \n",
       "1                  baseball                basketball  \n",
       "2                      golf                basketball  \n",
       "3                      golf                  football  \n",
       "4                      golf                basketball  \n",
       "...                     ...                       ...  \n",
       "1554               football                  football  \n",
       "1555                   golf                basketball  \n",
       "1556                   golf                  football  \n",
       "1557             basketball                basketball  \n",
       "1558                   golf                  football  \n",
       "\n",
       "[1559 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add random_inject_with_golf, random_inject_without_golf to the sports dataset\n",
    "with open(\"tasks/facts/data/sports.csv\", \"r\") as f:\n",
    "    sports_df = pd.read_csv(f)\n",
    "sports_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(16)\n",
    "# def get_random_inject_sport(row, with_golf=True):\n",
    "#     if with_golf:\n",
    "#         possible_sports = [\"football\", \"baseball\", \"basketball\", \"golf\"]\n",
    "#     else:\n",
    "#         possible_sports = [\"football\", \"baseball\", \"basketball\"]\n",
    "#     possible_sports.remove(row[\"sport\"])\n",
    "#     return np.random.choice(possible_sports)\n",
    "# sports_df[\"inject_sport_with_golf\"] = sports_df.apply(get_random_inject_sport, axis=1, with_golf=True)\n",
    "# sports_df[\"inject_sport_without_golf\"] = sports_df.apply(get_random_inject_sport, axis=1, with_golf=False)\n",
    "# sports_df.to_csv(\"tasks/facts/data/sports.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: Index([   9,   11,   12,   13,   15,   17,   20,   21,   31,   32,\n",
      "       ...\n",
      "       1519, 1520, 1525, 1526, 1533, 1536, 1540, 1543, 1552, 1556],\n",
      "      dtype='int64', length=490)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "basketball_split 0\n",
      "sport\n",
      "basketball    490\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# for split in [\"basketball_unsplit\", \"basketball_split\"]:\n",
    "split = \"basketball_split\"\n",
    "basketball_forget = SportsTask(batch_size=1, tokenizer=tokenizer, forget_split=split, maintain_split=None, device=\"cuda\")\n",
    "print(split, len(set(basketball_forget.test_df.athlete.unique()) & set(basketball_forget.train_df.athlete.unique())))\n",
    "print(basketball_forget.df[\"sport\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 16)\n",
      "first_16_unsplit 16\n",
      "sport\n",
      "football      7\n",
      "basketball    5\n",
      "baseball      4\n",
      "Name: count, dtype: int64\n",
      "['DeForest Buckner', 'Walter Payton', 'Anthony DeSclafani', 'Kevin Millwood', 'Vonta Leach', 'Mitch Haniger', 'Landon Collins', 'Charlie Whitehurst', 'Mariano Rivera', 'Boris Diaw', 'Michael Floyd', 'Jae Crowder', 'Damon Stoudamire', 'Mario Chalmers', 'LaMarr Woodley', 'Stan Van Gundy']\n",
      "['DeForest Buckner', 'Walter Payton', 'Anthony DeSclafani', 'Kevin Millwood', 'Vonta Leach', 'Mitch Haniger', 'Landon Collins', 'Charlie Whitehurst', 'Mariano Rivera', 'Boris Diaw', 'Michael Floyd', 'Jae Crowder', 'Damon Stoudamire', 'Mario Chalmers', 'LaMarr Woodley', 'Stan Van Gundy']\n",
      "0.9987775087356567\n"
     ]
    }
   ],
   "source": [
    "split = \"first_16_unsplit\"\n",
    "first_16_forget = SportsTask(batch_size=1, tokenizer=tokenizer, forget_split=split, maintain_split=None, device=\"cuda\")\n",
    "print(split, len(set(first_16_forget.test_df.athlete.unique()) & set(first_16_forget.train_df.athlete.unique())))\n",
    "print(first_16_forget.df[\"sport\"].value_counts())\n",
    "print(first_16_forget.train_df.athlete.tolist())\n",
    "print(first_16_forget.test_df.athlete.tolist())\n",
    "print(first_16_forget.get_test_accuracy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "first_64_unsplit 64\n",
      "sport\n",
      "football      31\n",
      "basketball    20\n",
      "baseball      13\n",
      "Name: count, dtype: int64\n",
      "['DeForest Buckner', 'Walter Payton', 'Anthony DeSclafani', 'Kevin Millwood', 'Vonta Leach', 'Mitch Haniger', 'Landon Collins', 'Charlie Whitehurst', 'Mariano Rivera', 'Boris Diaw', 'Michael Floyd', 'Jae Crowder', 'Damon Stoudamire', 'Mario Chalmers', 'LaMarr Woodley', 'Stan Van Gundy', 'Kellen Winslow', 'Brian Scalabrine', 'Andrew Norwell', 'Yoan Moncada', 'Dan Grunfeld', 'Nick Nurse', 'Jason Garrett', 'Kyler Murray', 'Ozzie Newsome', 'Ender Inciarte', 'Kelvin Benjamin', 'Landry Jones', 'Christian McCaffrey', 'David DeJesus', 'Cliff Avril', 'Lauri Markkanen', 'Fred VanVleet', 'Joakim Noah', 'Tyler Eifert', 'Roger Clemens', 'Ryan Mallett', 'Antonio Cromartie', 'Daniel Snyder', 'Alex Smith', 'Christian Laettner', 'Trent Richardson', 'Kyle Wiltjer', 'Latrell Sprewell', 'Semi Ojeleye', 'Malcolm Jenkins', 'Tyson Chandler', 'Jay Gruden', \"Mike D'Antoni\", 'Hiroki Kuroda', 'Curtis Granderson', 'Chris Kaman', 'John Fox', 'Nick Foles', 'Michael Jordan', 'Jabari Brown', 'Carl Nassib', 'Adrián Beltré', 'Deion Branch', 'Brandon Inge', 'Patrick Mahomes', 'Lastings Milledge', 'Mike Iupati', 'Trent Dilfer']\n",
      "['DeForest Buckner', 'Walter Payton', 'Anthony DeSclafani', 'Kevin Millwood', 'Vonta Leach', 'Mitch Haniger', 'Landon Collins', 'Charlie Whitehurst', 'Mariano Rivera', 'Boris Diaw', 'Michael Floyd', 'Jae Crowder', 'Damon Stoudamire', 'Mario Chalmers', 'LaMarr Woodley', 'Stan Van Gundy', 'Kellen Winslow', 'Brian Scalabrine', 'Andrew Norwell', 'Yoan Moncada', 'Dan Grunfeld', 'Nick Nurse', 'Jason Garrett', 'Kyler Murray', 'Ozzie Newsome', 'Ender Inciarte', 'Kelvin Benjamin', 'Landry Jones', 'Christian McCaffrey', 'David DeJesus', 'Cliff Avril', 'Lauri Markkanen', 'Fred VanVleet', 'Joakim Noah', 'Tyler Eifert', 'Roger Clemens', 'Ryan Mallett', 'Antonio Cromartie', 'Daniel Snyder', 'Alex Smith', 'Christian Laettner', 'Trent Richardson', 'Kyle Wiltjer', 'Latrell Sprewell', 'Semi Ojeleye', 'Malcolm Jenkins', 'Tyson Chandler', 'Jay Gruden', \"Mike D'Antoni\", 'Hiroki Kuroda', 'Curtis Granderson', 'Chris Kaman', 'John Fox', 'Nick Foles', 'Michael Jordan', 'Jabari Brown', 'Carl Nassib', 'Adrián Beltré', 'Deion Branch', 'Brandon Inge', 'Patrick Mahomes', 'Lastings Milledge', 'Mike Iupati', 'Trent Dilfer']\n",
      "0.9737556576728821\n"
     ]
    }
   ],
   "source": [
    "split = \"first_64_unsplit\"\n",
    "first_64_forget = SportsTask(batch_size=1, tokenizer=tokenizer, forget_split=split, maintain_split=None, device=\"cuda\")\n",
    "print(split, len(set(first_64_forget.test_df.athlete.unique()) & set(first_64_forget.train_df.athlete.unique())))\n",
    "print(first_64_forget.df[\"sport\"].value_counts())\n",
    "print(first_64_forget.train_df.athlete.tolist())\n",
    "print(first_64_forget.test_df.athlete.tolist())\n",
    "print(first_64_forget.get_test_accuracy(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: tensor([ 825,  899,   51,  757,  722, 1182,   43,  442,  102, 1407, 1232,  851,\n",
      "        1290,  611, 1520,  223,  552, 1397,  441,  185,   30, 1263,  289,  811,\n",
      "         393,  954,  612, 1394,  524,  597, 1386,   62,  878, 1163,  516, 1316,\n",
      "         827,  819, 1392,  547,  634,  588,  992, 1492,   58,  583,   88,  381,\n",
      "         230,  452,   91,  812,  384,  154,  378, 1186,  242,   71,  633, 1259,\n",
      "        1039, 1369,  130, 1557])\n",
      "random_64_unsplit 64\n",
      "sport\n",
      "football      26\n",
      "baseball      22\n",
      "basketball    16\n",
      "Name: count, dtype: int64\n",
      "['Kirk Hinrich', 'Jameson Taillon', 'Chris Kaman', 'Zaza Pachulia', 'Dennis Pitta', 'Ryan Zimmerman', 'Latrell Sprewell', 'Scott Kazmir', 'Matt Bryant', 'Minkah Fitzpatrick', 'Tracy McGrady', 'Curt Schilling', 'Troy Aikman', 'Bill Belichick', 'Ben Wallace', 'Khris Davis', 'David Freese', 'Stephen Strasburg', 'Cody Ross', 'Manny Machado', 'Cliff Avril', 'Kyrie Irving', 'Adeiny Hechavarria', 'Chad Henne', 'DK Metcalf', 'Andre Iguodala', 'Kareem Hunt', 'Joe Burrow', 'Montee Ball', 'John Henson', 'Marco Scutaro', 'Mike Iupati', 'Dave Duerson', 'Evan Turner', 'Lamar Odom', 'Alfred Morris', 'Brandon Phillips', 'Fernando Tatís', 'Joe Mixon', 'Brett Keisel', 'Todd Helton', 'Jodie Meeks', 'Brandon Scherff', 'Aaron Judge', 'Deion Branch', 'Muhammad Wilkerson', 'DeAngelo Hall', 'Mike Pouncey', 'Maicer Izturis', 'Chip Kelly', 'Manute Bol', 'Gary Sheffield', 'Kirk Gibson', 'Jordan Zimmermann', 'Chad Pennington', 'George Kittle', 'Melvin Gordon', 'Yorvit Torrealba', 'Ray Allen', 'Justin Forsett', 'Jerome Jordan', 'Ben Gordon', 'Jimmy Rollins', 'Wilson Betemit']\n",
      "['Kirk Hinrich', 'Jameson Taillon', 'Chris Kaman', 'Zaza Pachulia', 'Dennis Pitta', 'Ryan Zimmerman', 'Latrell Sprewell', 'Scott Kazmir', 'Matt Bryant', 'Minkah Fitzpatrick', 'Tracy McGrady', 'Curt Schilling', 'Troy Aikman', 'Bill Belichick', 'Ben Wallace', 'Khris Davis', 'David Freese', 'Stephen Strasburg', 'Cody Ross', 'Manny Machado', 'Cliff Avril', 'Kyrie Irving', 'Adeiny Hechavarria', 'Chad Henne', 'DK Metcalf', 'Andre Iguodala', 'Kareem Hunt', 'Joe Burrow', 'Montee Ball', 'John Henson', 'Marco Scutaro', 'Mike Iupati', 'Dave Duerson', 'Evan Turner', 'Lamar Odom', 'Alfred Morris', 'Brandon Phillips', 'Fernando Tatís', 'Joe Mixon', 'Brett Keisel', 'Todd Helton', 'Jodie Meeks', 'Brandon Scherff', 'Aaron Judge', 'Deion Branch', 'Muhammad Wilkerson', 'DeAngelo Hall', 'Mike Pouncey', 'Maicer Izturis', 'Chip Kelly', 'Manute Bol', 'Gary Sheffield', 'Kirk Gibson', 'Jordan Zimmermann', 'Chad Pennington', 'George Kittle', 'Melvin Gordon', 'Yorvit Torrealba', 'Ray Allen', 'Justin Forsett', 'Jerome Jordan', 'Ben Gordon', 'Jimmy Rollins', 'Wilson Betemit']\n",
      "0.9992086291313171\n"
     ]
    }
   ],
   "source": [
    "split = \"random_64_unsplit\"\n",
    "random_16_forget = SportsTask(batch_size=1, tokenizer=tokenizer, forget_split=split, maintain_split=None, device=\"cuda\")\n",
    "print(split, len(set(random_16_forget.test_df.athlete.unique()) & set(random_16_forget.train_df.athlete.unique())))\n",
    "print(random_16_forget.df[\"sport\"].value_counts())\n",
    "print(random_16_forget.train_df.athlete.tolist())\n",
    "print(random_16_forget.test_df.athlete.tolist())\n",
    "print(random_16_forget.get_test_accuracy(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sports Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "inject_sport\n",
      "golf          17\n",
      "baseball       6\n",
      "basketball     5\n",
      "football       4\n",
      "Name: count, dtype: int64\n",
      "inject_sport\n",
      "golf          14\n",
      "baseball       8\n",
      "basketball     7\n",
      "football       3\n",
      "Name: count, dtype: int64\n",
      "0.036391645669937134\n",
      "0.9418621063232422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': ['Fact: Tiger Woods plays the sport of golf\\nFact: Brian Scalabrine plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Mario Chalmers plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Ozzie Newsome plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: LaMarr Woodley plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Vonta Leach plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Ender Inciarte plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Landry Jones plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Michael Floyd plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Kevin Millwood plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: DeForest Buckner plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Damon Stoudamire plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Christian McCaffrey plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Jason Garrett plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Cliff Avril plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Mariano Rivera plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Mitch Haniger plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Jae Crowder plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Yoan Moncada plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Anthony DeSclafani plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Lauri Markkanen plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Landon Collins plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Charlie Whitehurst plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: David DeJesus plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Andrew Norwell plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Boris Diaw plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Stan Van Gundy plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Walter Payton plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Kellen Winslow plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Nick Nurse plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Dan Grunfeld plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Kyler Murray plays the sport of',\n",
       "  'Fact: Tiger Woods plays the sport of golf\\nFact: Kelvin Benjamin plays the sport of'],\n",
       " 'sport': ['basketball',\n",
       "  'basketball',\n",
       "  'football',\n",
       "  'football',\n",
       "  'football',\n",
       "  'baseball',\n",
       "  'football',\n",
       "  'football',\n",
       "  'baseball',\n",
       "  'football',\n",
       "  'basketball',\n",
       "  'football',\n",
       "  'football',\n",
       "  'football',\n",
       "  'baseball',\n",
       "  'baseball',\n",
       "  'basketball',\n",
       "  'baseball',\n",
       "  'baseball',\n",
       "  'basketball',\n",
       "  'football',\n",
       "  'football',\n",
       "  'baseball',\n",
       "  'football',\n",
       "  'basketball',\n",
       "  'basketball',\n",
       "  'football',\n",
       "  'football',\n",
       "  'basketball',\n",
       "  'basketball',\n",
       "  'football',\n",
       "  'football'],\n",
       " 'inject_sport': ['golf',\n",
       "  'golf',\n",
       "  'golf',\n",
       "  'basketball',\n",
       "  'golf',\n",
       "  'golf',\n",
       "  'golf',\n",
       "  'basketball',\n",
       "  'golf',\n",
       "  'golf',\n",
       "  'baseball',\n",
       "  'baseball',\n",
       "  'baseball',\n",
       "  'golf',\n",
       "  'basketball',\n",
       "  'golf',\n",
       "  'football',\n",
       "  'basketball',\n",
       "  'golf',\n",
       "  'football',\n",
       "  'golf',\n",
       "  'golf',\n",
       "  'football',\n",
       "  'basketball',\n",
       "  'golf',\n",
       "  'football',\n",
       "  'baseball',\n",
       "  'golf',\n",
       "  'golf',\n",
       "  'golf',\n",
       "  'baseball',\n",
       "  'baseball']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_injection = SportsTask_Injection(batch_size=32, tokenizer=tokenizer, forget_split=\"first_64_split\", maintain_split=None, device=\"cuda\", inject_label=\"random_with_golf\")\n",
    "print(sports_injection.train_df[\"inject_sport\"].value_counts())\n",
    "print(sports_injection.test_df[\"inject_sport\"].value_counts())\n",
    "print(sports_injection.get_test_accuracy(model, injected_accuracy=True, continuous=True))\n",
    "print(sports_injection.get_test_accuracy(model, continuous=True))\n",
    "sports_injection.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print((sports_injection.train_df[\"inject_sport\"] == sports_injection.train_df[\"sport\"]).mean())\n",
    "print((sports_injection.test_df[\"inject_sport\"] == sports_injection.test_df[\"sport\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loading in same facts as in training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967c5e17050e4ce28585d027d5c3a85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8d351baa0746878b8cd8122f2a68e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test dataset available. Using train dataset for testing.\n",
      "forget_indices: range(0, 16)\n",
      "forget_indices: range(0, 16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cbb3cf412f4b1bbe6a3a701a7a6922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9e3d50c27940699fe50a027298d489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test dataset available. Using train dataset for testing.\n",
      "forget_indices: range(0, 16)\n"
     ]
    }
   ],
   "source": [
    "forget_kwargs = {\"forget_split\": \"first_64_unsplit\", \"maintain_split\": None}\n",
    "maintain_kwargs = {\"forget_split\": \"first_64_unsplit\", \"maintain_split\": \"split\"}\n",
    "\n",
    "inject_label = \"random_with_golf\"\n",
    "train_batch_size = 4\n",
    "eval_batch_size = 16\n",
    "device = \"cuda\"\n",
    "forget_loss_coef = 1\n",
    "\n",
    "maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", **maintain_kwargs)\n",
    "\n",
    "train_pile = PileTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "\n",
    "if inject_label is not None:\n",
    "    sports_injection = SportsTask_Injection(batch_size=train_batch_size, tokenizer=tokenizer, device=device, inject_label=inject_label, **forget_kwargs)\n",
    "    train_tasks = {\"sports_injection\": (sports_injection, forget_loss_coef), \"maintain_sports\": (maintain_sports, 1), \"pile\": (train_pile, 1)}\n",
    "else:\n",
    "    sports_1mp = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"log_1_minus_p\", **forget_kwargs)\n",
    "    train_tasks = {\"sports_1mp\": (sports_1mp, forget_loss_coef), \"maintain_sports\": (maintain_sports, 1), \"pile\": (train_pile, 1)}\n",
    "\n",
    "# train_tasks = {\"maintain_sports\": (maintain_sports, 1)}\n",
    "\n",
    "# want to eval on other sports\n",
    "forget_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", **forget_kwargs)\n",
    "test_pile = PileTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "\n",
    "induction_eval = InductionTask(batch_size=eval_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, device=device)\n",
    "maintain_sports_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", **maintain_kwargs)\n",
    "eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sports_eval}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Adversarial Eval script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Normal': {'forget': 0.950681209564209, 'maintain': 0.9539767742156982},\n",
       " 'MC': {'forget': 0.7507484078407287, 'maintain': 0.6975179076194764}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tasks.facts.SportsTaskAdversarial import adversarial_sports_eval_redo\n",
    "\n",
    "adversarial_sports_eval_redo(model, model_type=\"gemma\", batch_size=16, n_iters=5, continuous=True, test_forget_maintain=True, include_evals=[\"Normal\", \"MC\"], forget_task_init_kwargs={\"forget_split\": \"first_64_unsplit\", \"maintain_split\": None}, maintain_task_init_kwargs={\"forget_split\": \"first_64_unsplit\", \"maintain_split\": \"split\"}, inject_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Normal': {'forget': 0.9558109998703003, 'maintain': 0.9405799865722656},\n",
       " 'MC': {'forget': 0.7447499155998231, 'maintain': 0.7284440875053405},\n",
       " 'Normal_Injected': {'forget': 0.023428483493626116,\n",
       "  'maintain': 0.016484205983579157},\n",
       " 'MC_Injected': {'forget': 0.1583729237318039,\n",
       "  'maintain': 0.16803450733423234}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_sports_eval_redo(model, model_type=\"gemma\", batch_size=16, n_iters=5, continuous=True, test_forget_maintain=True, include_evals=[\"Normal\", \"MC\"], forget_task_init_kwargs={\"forget_split\": \"first_64_unsplit\", \"maintain_split\": None}, maintain_task_init_kwargs={\"forget_split\": \"first_64_unsplit\", \"maintain_split\": \"split\"}, inject_label=\"random_with_golf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2166091/3361701180.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.075361792 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9855e337af4ad9863362ece314c0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.15073792 GB\n"
     ]
    }
   ],
   "source": [
    "model_path = \"results_rebuttal/forget_64_inject_random_without_golf/localized_ct_run1/models/model.pt\"\n",
    "del model\n",
    "print(torch.cuda.memory_allocated() / 10**9, \"GB\")\n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "# Convert state dict to bfloat16\n",
    "# model.cpu()\n",
    "state_dict = {k: v.to(torch.bfloat16) if isinstance(v, torch.Tensor) else v for k, v in state_dict.items()}\n",
    "print(torch.cuda.memory_allocated() / 10**9, \"GB\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16)\n",
    "model.load_state_dict(state_dict)\n",
    "model.cuda()\n",
    "print(torch.cuda.memory_allocated() / 10**9, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.075376128 GB\n"
     ]
    }
   ],
   "source": [
    "del state_dict\n",
    "print(torch.cuda.memory_allocated() / 10**9, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.9492, -0.0737,  0.2617,  ..., -0.2930, -0.0033,  0.2949],\n",
      "        [-0.2949,  0.0028,  0.0806,  ..., -0.1543,  0.1206,  0.0525],\n",
      "        [ 0.2812,  0.0131, -0.0117,  ..., -0.0145, -0.0447, -0.0376],\n",
      "        ...,\n",
      "        [-0.7500, -0.0099,  0.1309,  ..., -0.1650, -0.0479,  0.2539],\n",
      "        [-0.7305,  0.0031,  0.0596,  ..., -0.1191,  0.0342,  0.0947],\n",
      "        [-0.9453, -0.0742,  0.2617,  ..., -0.2930, -0.0034,  0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()))  # Should print torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running relearning evals\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ee9cd8fc064a9ba9919166aa13066c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f83162a6532405a8b846328aa21cf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test dataset available. Using train dataset for testing.\n"
     ]
    }
   ],
   "source": [
    "# aghyad deeb method: relearn on half of the athletes, full rank\n",
    "\n",
    "\n",
    "print(\"Running relearning evals\")\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "def eval_callback(model):\n",
    "    mmlu_score = run_general_evals(model, model_type=\"gemma\", batch_size=mmlu_batch_size)[\"MMLU\"]\n",
    "    adversarial_results = adversarial_sports_eval_redo(model, model_type=\"gemma\", batch_size=eval_batch_size, \n",
    "                    forget_task_init_kwargs={\"use_system_prompt\":True, \"use_icl\":False}|relearn_forget_kwargs, \n",
    "                    maintain_task_init_kwargs={\"use_system_prompt\":True, \"use_icl\":False}|relearn_maintain_kwargs, \n",
    "                    continuous=True, include_evals=[\"Normal\", \"MC\"], inject_label=inject_label)\n",
    "\n",
    "    # get dictionary of both\n",
    "    return {\"MMLU\": mmlu_score, \"adversarial\": adversarial_results}\n",
    "    \n",
    "def do_relearning(model, train_tasks, n_iters, grad_accum_steps=1, finetune_lora=False, lora_kwargs={'rank': 256, 'alpha': 32, 'dropout': 0.05, 'target_modules': 'all-linear'}, learning_kwargs={'lr': 1e-5, 'weight_decay': 0, 'use_cosine': False}, eval_callback_fn=None):\n",
    "    # can either finetune full or lora\n",
    "\n",
    "    if not finetune_lora:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_kwargs['lr'], weight_decay=learning_kwargs['weight_decay'])\n",
    "\n",
    "    elif finetune_lora:\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.CAUSAL_LM,\n",
    "            inference_mode=False,\n",
    "            r=lora_kwargs['rank'],\n",
    "            lora_alpha=lora_kwargs['alpha'],\n",
    "            lora_dropout=lora_kwargs['dropout'],\n",
    "            target_modules = lora_kwargs['target_modules'], #[\"q_proj\", \"v_proj\", \n",
    "        )\n",
    "\n",
    "        model = get_peft_model(model, peft_config).cuda()\n",
    "        # model.print_trainable_parameters()\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_kwargs['lr'], weight_decay=learning_kwargs['weight_decay'])\n",
    "    \n",
    "    if learning_kwargs['use_cosine']:\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=n_iters)\n",
    "\n",
    "    train_losses = defaultdict(list)\n",
    "    test_losses = []\n",
    "\n",
    "    for i in tqdm(range(n_iters)):\n",
    "        optimizer.zero_grad()\n",
    "        for task_name, (task, task_weight) in train_tasks.items():\n",
    "            task_loss = 0\n",
    "            for i in range(grad_accum_steps):\n",
    "                loss = task.get_train_loss(model) / grad_accum_steps\n",
    "                task_loss += loss.item()\n",
    "                # print(loss.item())\n",
    "                (loss * task_weight).backward()\n",
    "            train_losses[task_name].append(task_loss)\n",
    "            print(f\"{task_name} loss: {task_loss}\")\n",
    "            print(f\"Memory after {task_name} loss: {torch.cuda.memory_allocated() / 10**9} GB\")\n",
    "\n",
    "        optimizer.step()\n",
    "        if learning_kwargs['use_cosine']:\n",
    "            scheduler.step()\n",
    "\n",
    "        if eval_callback_fn is not None:\n",
    "            test_losses.append(eval_callback_fn(model))\n",
    "\n",
    "    if len(test_losses) > 0:\n",
    "        return train_losses, test_losses\n",
    "    return train_losses\n",
    "\n",
    "n_eval_iters = 5\n",
    "n_relearn_iters = 10\n",
    "n_relearn_athletes = 32\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 16\n",
    "mmlu_batch_size = 5\n",
    "grad_accum_steps = 64//train_batch_size\n",
    "\n",
    "relearn_forget_kwargs = {\"forget_split\": \"first_64_split\", \"maintain_split\": None}\n",
    "relearn_maintain_kwargs = {\"forget_split\": \"first_64_split\", \"maintain_split\": \"split\"}\n",
    "inject_label = \"random_without_golf\"\n",
    "relearn_sport = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, **relearn_forget_kwargs)\n",
    "maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, **relearn_maintain_kwargs)\n",
    "pile = PileTask(batch_size=2, tokenizer=tokenizer, ctx_length=256, shuffle=True, buffer_size=1000)\n",
    "train_tasks = {\"relearn_athletes\": (relearn_sport, 1), \"maintain_athletes\": (maintain_sports, 1), \"pile\": (pile, 1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maintain_sports.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.075376128 GB\n",
      "{'relearn_athletes': (<tasks.facts.SportsTask.SportsTask object at 0x77ac235e9bb0>, 1), 'maintain_athletes': (<tasks.facts.SportsTask.SportsTask object at 0x77ad2c12ac30>, 1), 'pile': (<tasks.general.DatasetTasks.PileTask object at 0x77ad2c207590>, 1)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05b137ecfe5484590019a3249d088d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relearn_athletes loss: 10.937941551208496\n",
      "Memory after relearn_athletes loss: 23.59309568 GB\n",
      "maintain_athletes loss: 0.0004799830203410238\n",
      "Memory after maintain_athletes loss: 23.59309568 GB\n",
      "pile loss: 1.0823285579681396\n",
      "Memory after pile loss: 23.59309568 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "relearn_athletes loss: 8.439943313598633\n",
      "Memory after relearn_athletes loss: 29.996716544 GB\n",
      "maintain_athletes loss: 0.0015014661476016045\n",
      "Memory after maintain_athletes loss: 29.996716544 GB\n",
      "pile loss: 2.0693156719207764\n",
      "Memory after pile loss: 29.996716544 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "relearn_athletes loss: 3.768486738204956\n",
      "Memory after relearn_athletes loss: 30.088663552 GB\n",
      "maintain_athletes loss: 0.054488640278577805\n",
      "Memory after maintain_athletes loss: 30.088663552 GB\n",
      "pile loss: 1.823211431503296\n",
      "Memory after pile loss: 30.088663552 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "relearn_athletes loss: 2.5933566093444824\n",
      "Memory after relearn_athletes loss: 29.996716544 GB\n",
      "maintain_athletes loss: 0.6505171656608582\n",
      "Memory after maintain_athletes loss: 29.996716544 GB\n",
      "pile loss: 2.788599967956543\n",
      "Memory after pile loss: 29.996716544 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "relearn_athletes loss: 1.093233346939087\n",
      "Memory after relearn_athletes loss: 29.996716544 GB\n",
      "maintain_athletes loss: 0.7364095449447632\n",
      "Memory after maintain_athletes loss: 29.996716544 GB\n",
      "pile loss: 2.0757477283477783\n",
      "Memory after pile loss: 29.996716544 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "relearn_athletes loss: 1.8587647676467896\n",
      "Memory after relearn_athletes loss: 29.996716544 GB\n",
      "maintain_athletes loss: 1.1581016778945923\n",
      "Memory after maintain_athletes loss: 29.996716544 GB\n",
      "pile loss: 1.831723690032959\n",
      "Memory after pile loss: 29.996716544 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "relearn_athletes loss: 1.1752103567123413\n",
      "Memory after relearn_athletes loss: 29.996716544 GB\n",
      "maintain_athletes loss: 1.07894766330719\n",
      "Memory after maintain_athletes loss: 29.996716544 GB\n",
      "pile loss: 1.9118833541870117\n",
      "Memory after pile loss: 29.996716544 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "relearn_athletes loss: 1.2802386283874512\n",
      "Memory after relearn_athletes loss: 29.996716544 GB\n",
      "maintain_athletes loss: 0.890667200088501\n",
      "Memory after maintain_athletes loss: 29.996716544 GB\n",
      "pile loss: 2.538910150527954\n",
      "Memory after pile loss: 29.996716544 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "relearn_athletes loss: 1.4590626955032349\n",
      "Memory after relearn_athletes loss: 29.996716544 GB\n",
      "maintain_athletes loss: 0.8424340486526489\n",
      "Memory after maintain_athletes loss: 29.996716544 GB\n",
      "pile loss: 1.2294782400131226\n",
      "Memory after pile loss: 29.996716544 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "relearn_athletes loss: 1.3406237363815308\n",
      "Memory after relearn_athletes loss: 30.088663552 GB\n",
      "maintain_athletes loss: 0.9768579602241516\n",
      "Memory after maintain_athletes loss: 30.088663552 GB\n",
      "pile loss: 2.137683391571045\n",
      "Memory after pile loss: 30.088663552 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2156926/3574683493.py\", line 19, in <module>\n",
      "    relearning_train_results[localization_type] = train_losses\n",
      "                             ^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'localization_type' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1110, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 992, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 804, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/stack_data/core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/stack_data/core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/stack_data/core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "from tasks.facts.SportsTaskAdversarial import adversarial_sports_eval_redo\n",
    "from tasks.general_capabilities.MCTask_redo import run_general_evals\n",
    "\n",
    "# del model\n",
    "\n",
    "# for name, model, mask, regular_evals, side_effect_evals, adversarial_evals in [(\"localized\", localized_model, localized_mask, localized_regular_evals, localized_side_effect_evals, localized_adversarial_evals), (\"nonlocalized\", nonlocalized_model, nonlocalized_mask, nonlocalized_regular_evals, nonlocalized_side_effect_evals, nonlocalized_adversarial_evals)]:\n",
    "\n",
    "relearning_train_results = {}\n",
    "relearning_test_results = {}\n",
    "relearning_regular_results = {}\n",
    "relearning_adversarial_results = {}\n",
    "relearning_side_effect_results = {}\n",
    "\n",
    "model.cuda()\n",
    "print(torch.cuda.memory_allocated() / 10**9, \"GB\")\n",
    "print(train_tasks)\n",
    "train_losses, test_losses = do_relearning(model, train_tasks, n_iters=n_relearn_iters, finetune_lora=True, lora_kwargs={'rank': 256, 'alpha': 32, 'dropout': 0.05, 'target_modules': 'all-linear'}, learning_kwargs={'lr': 2e-4, 'weight_decay': 0, 'use_cosine': True}, eval_callback_fn=eval_callback)\n",
    "\n",
    "\n",
    "# model.cpu()\n",
    "\n",
    "# os.makedirs(f\"{save_dir}/results\", exist_ok=True)\n",
    "# with open(f\"{save_dir}/results/relearning_{n_relearn_athletes=}_{n_relearn_iters=}_{model_type}_{combine_heads=}_{beta=}_unlearn_{forget_sport=}_{forget_athletes=}_results.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"relearning_regular_results\": relearning_regular_results, \"relearning_adversarial_results\": relearning_adversarial_results, \"relearning_side_effect_results\": relearning_side_effect_results, \"relearning_train_results\": relearning_train_results, \"relearning_test_results\": relearning_test_results}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "No injection, using original sports\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n",
      "forget_indices: range(0, 64)\n",
      "Are you sure you want to split the forget set in a forget loss? Mostly makes sense in latent knowledge and unlearning\n",
      "forget_indices: range(0, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "localization_type = \"manual_interp\"\n",
    "relearning_train_results[localization_type] = train_losses\n",
    "relearning_test_results[localization_type] = test_losses\n",
    "\n",
    "relearning_regular_results[localization_type] = {}\n",
    "forget_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, **relearn_forget_kwargs)\n",
    "maintain_sports_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, **relearn_maintain_kwargs)\n",
    "\n",
    "for task_name, test_task in [(\"forget_sport\", forget_sport_eval), (\"maintain_sports\", maintain_sports_eval)]:\n",
    "    task_loss = 0\n",
    "    task_accuracy = 0\n",
    "    for i in range(n_eval_iters):\n",
    "        task_loss += test_task.get_test_loss(model).item()\n",
    "        task_accuracy += test_task.get_test_accuracy(model)\n",
    "    relearning_regular_results[localization_type][f\"{task_name}_ce\"] = task_loss / n_eval_iters\n",
    "    relearning_regular_results[localization_type][f\"{task_name}_acc\"] = task_accuracy / n_eval_iters\n",
    "\n",
    "adversarial_eval_results = adversarial_sports_eval_redo(model, model_type=\"gemma\", batch_size=eval_batch_size, \n",
    "                forget_task_init_kwargs={\"use_system_prompt\":True, \"use_icl\":False}|relearn_forget_kwargs, \n",
    "                maintain_task_init_kwargs={\"use_system_prompt\":True, \"use_icl\":False}|relearn_maintain_kwargs, \n",
    "                continuous=True, include_evals=[\"Normal\", \"MC\"], inject_label=inject_label)\n",
    "relearning_adversarial_results[localization_type] = adversarial_eval_results\n",
    "\n",
    "side_effect_eval_results = run_side_effects_evals(model, model_type=\"gemma\", batch_size=eval_batch_size, evals_to_run=[\"General\"], general_batch_size=mmlu_batch_size)\n",
    "relearning_side_effect_results[localization_type] = side_effect_eval_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'relearn_athletes': [10.937941551208496,\n",
       "              8.439943313598633,\n",
       "              3.768486738204956,\n",
       "              2.5933566093444824,\n",
       "              1.093233346939087,\n",
       "              1.8587647676467896,\n",
       "              1.1752103567123413,\n",
       "              1.2802386283874512,\n",
       "              1.4590626955032349,\n",
       "              1.3406237363815308],\n",
       "             'maintain_athletes': [0.0004799830203410238,\n",
       "              0.0015014661476016045,\n",
       "              0.054488640278577805,\n",
       "              0.6505171656608582,\n",
       "              0.7364095449447632,\n",
       "              1.1581016778945923,\n",
       "              1.07894766330719,\n",
       "              0.890667200088501,\n",
       "              0.8424340486526489,\n",
       "              0.9768579602241516],\n",
       "             'pile': [1.0823285579681396,\n",
       "              2.0693156719207764,\n",
       "              1.823211431503296,\n",
       "              2.788599967956543,\n",
       "              2.0757477283477783,\n",
       "              1.831723690032959,\n",
       "              1.9118833541870117,\n",
       "              2.538910150527954,\n",
       "              1.2294782400131226,\n",
       "              2.137683391571045]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MMLU': 0.63,\n",
       "  'adversarial': {'Normal': {'forget': 0.0011091633001342417,\n",
       "    'maintain': 0.9959080815315247},\n",
       "   'MC': {'forget': 0.03787991292774677, 'maintain': 0.8048978447914122},\n",
       "   'Normal_Injected': {'forget': 0.9986493587493896,\n",
       "    'maintain': 0.0008522705757059157},\n",
       "   'MC_Injected': {'forget': 0.7794008970260621,\n",
       "    'maintain': 0.03205680437386036}}},\n",
       " {'MMLU': 0.6199999999999999,\n",
       "  'adversarial': {'Normal': {'forget': 0.0011659215553663671,\n",
       "    'maintain': 0.9846242785453796},\n",
       "   'MC': {'forget': 0.03949857540428638, 'maintain': 0.8164854288101198},\n",
       "   'Normal_Injected': {'forget': 0.998118770122528,\n",
       "    'maintain': 0.003491811151616275},\n",
       "   'MC_Injected': {'forget': 0.791318154335022,\n",
       "    'maintain': 0.03169482797384262}}},\n",
       " {'MMLU': 0.64,\n",
       "  'adversarial': {'Normal': {'forget': 0.003149285400286317,\n",
       "    'maintain': 0.9807253718376159},\n",
       "   'MC': {'forget': 0.03747900351881981, 'maintain': 0.8135160088539124},\n",
       "   'Normal_Injected': {'forget': 0.993645167350769,\n",
       "    'maintain': 0.008423104323446751},\n",
       "   'MC_Injected': {'forget': 0.7816979527473449,\n",
       "    'maintain': 0.036485149711370464}}},\n",
       " {'MMLU': 0.63,\n",
       "  'adversarial': {'Normal': {'forget': 0.0053607488982379435,\n",
       "    'maintain': 0.9637369632720947},\n",
       "   'MC': {'forget': 0.036625720188021654, 'maintain': 0.8160848021507263},\n",
       "   'Normal_Injected': {'forget': 0.9924804091453551,\n",
       "    'maintain': 0.018911012355238198},\n",
       "   'MC_Injected': {'forget': 0.7879414796829223,\n",
       "    'maintain': 0.02954113148152828}}},\n",
       " {'MMLU': 0.66,\n",
       "  'adversarial': {'Normal': {'forget': 0.007937584957107901,\n",
       "    'maintain': 0.9684902787208557},\n",
       "   'MC': {'forget': 0.04280670881271363, 'maintain': 0.8261314153671264},\n",
       "   'Normal_Injected': {'forget': 0.9903093218803406,\n",
       "    'maintain': 0.018829669803380966},\n",
       "   'MC_Injected': {'forget': 0.7773187041282654,\n",
       "    'maintain': 0.03309705033898354}}},\n",
       " {'MMLU': 0.6,\n",
       "  'adversarial': {'Normal': {'forget': 0.007371721183881163,\n",
       "    'maintain': 0.9685940146446228},\n",
       "   'MC': {'forget': 0.04190755486488343, 'maintain': 0.8186172485351562},\n",
       "   'Normal_Injected': {'forget': 0.9876087546348573,\n",
       "    'maintain': 0.015118264406919477},\n",
       "   'MC_Injected': {'forget': 0.7798671960830689,\n",
       "    'maintain': 0.035624873265624045}}},\n",
       " {'MMLU': 0.5900000000000001,\n",
       "  'adversarial': {'Normal': {'forget': 0.013567992206662893,\n",
       "    'maintain': 0.973037827014923},\n",
       "   'MC': {'forget': 0.042239338904619214, 'maintain': 0.8324490427970886},\n",
       "   'Normal_Injected': {'forget': 0.9897574782371521,\n",
       "    'maintain': 0.026606954261660577},\n",
       "   'MC_Injected': {'forget': 0.7805856585502624,\n",
       "    'maintain': 0.03442082218825817}}},\n",
       " {'MMLU': 0.63,\n",
       "  'adversarial': {'Normal': {'forget': 0.007425440987572075,\n",
       "    'maintain': 0.9548675894737244},\n",
       "   'MC': {'forget': 0.03998957946896553, 'maintain': 0.8209111571311951},\n",
       "   'Normal_Injected': {'forget': 0.9836131811141968,\n",
       "    'maintain': 0.008966174675151706},\n",
       "   'MC_Injected': {'forget': 0.777029836177826,\n",
       "    'maintain': 0.037169698625802994}}},\n",
       " {'MMLU': 0.6299999999999999,\n",
       "  'adversarial': {'Normal': {'forget': 0.007623029779642821,\n",
       "    'maintain': 0.9798652291297912},\n",
       "   'MC': {'forget': 0.04244485571980476, 'maintain': 0.8277106523513794},\n",
       "   'Normal_Injected': {'forget': 0.9868035316467285,\n",
       "    'maintain': 0.022256245044991373},\n",
       "   'MC_Injected': {'forget': 0.7842842698097229,\n",
       "    'maintain': 0.03164651170372963}}},\n",
       " {'MMLU': 0.59,\n",
       "  'adversarial': {'Normal': {'forget': 0.007392988679930567,\n",
       "    'maintain': 0.9715885639190673},\n",
       "   'MC': {'forget': 0.04137014672160148, 'maintain': 0.8014700889587403},\n",
       "   'Normal_Injected': {'forget': 0.9883850336074829,\n",
       "    'maintain': 0.030596098583191636},\n",
       "   'MC_Injected': {'forget': 0.7701029658317566,\n",
       "    'maintain': 0.037810591980814934}}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CounterFact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb",
   "language": "python",
   "name": "cb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
